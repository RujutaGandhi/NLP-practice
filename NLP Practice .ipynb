{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Practice - Rujuta Gandhi\n",
    "\n",
    "You have been provided with a pickle file, containing 100 news articles about some company.  Use appropriate topic modeling technique to identify top N most important topics.\n",
    "\n",
    "- read_pickle(directory+file.pkl')\n",
    "- Present top N most important topics in these news articles\n",
    "- Select N to identify relevant topics, but minimize duplication\n",
    "- Explain how you selected N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import string\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import pyLDAvis.gensim\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawled</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-30T18:28:45.012+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>Avery Dennison's (AVY) Q4 results are likely t...</td>\n",
       "      <td>IRobot downgraded to neutral from buy at Sidot...</td>\n",
       "      <td>http://omgili.com/ri/.wHSUbtEfZQRfU.5KUm1RkeXy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-30T18:29:07.001+02:00</td>\n",
       "      <td>french</td>\n",
       "      <td>1m95, c’est trop grand. Et sa stature, Bertran...</td>\n",
       "      <td>\"Bertrand Zibi Abeghe, encore prisonnier, et t...</td>\n",
       "      <td>http://omgili.com/ri/.wHSUbtEfZTpzFtnXyQJIwJ.j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-30T18:29:40.000+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>Tuggers and Topper Industrial Carts Help Trans...</td>\n",
       "      <td>Tuggers and Topper Industrial Carts Help Trans...</td>\n",
       "      <td>http://omgili.com/ri/jHIAmI4hxg.zDiulpymXqU_n4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-30T18:30:05.007+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>Currently adding the following games:\\n100 (by...</td>\n",
       "      <td></td>\n",
       "      <td>http://omgili.com/ri/.0rSU5LtMgyggHgoOVy9TMDWT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-30T18:30:05.013+02:00</td>\n",
       "      <td>english</td>\n",
       "      <td>Quote: : » Currently adding the following game...</td>\n",
       "      <td></td>\n",
       "      <td>http://omgili.com/ri/.0rSU5LtMgyggHgoOVy9TMDWT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         crawled language  \\\n",
       "0  2018-01-30T18:28:45.012+02:00  english   \n",
       "1  2018-01-30T18:29:07.001+02:00   french   \n",
       "2  2018-01-30T18:29:40.000+02:00  english   \n",
       "3  2018-01-30T18:30:05.007+02:00  english   \n",
       "4  2018-01-30T18:30:05.013+02:00  english   \n",
       "\n",
       "                                                text  \\\n",
       "0  Avery Dennison's (AVY) Q4 results are likely t...   \n",
       "1  1m95, c’est trop grand. Et sa stature, Bertran...   \n",
       "2  Tuggers and Topper Industrial Carts Help Trans...   \n",
       "3  Currently adding the following games:\\n100 (by...   \n",
       "4  Quote: : » Currently adding the following game...   \n",
       "\n",
       "                                               title  \\\n",
       "0  IRobot downgraded to neutral from buy at Sidot...   \n",
       "1  \"Bertrand Zibi Abeghe, encore prisonnier, et t...   \n",
       "2  Tuggers and Topper Industrial Carts Help Trans...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                 url  \n",
       "0  http://omgili.com/ri/.wHSUbtEfZQRfU.5KUm1RkeXy...  \n",
       "1  http://omgili.com/ri/.wHSUbtEfZTpzFtnXyQJIwJ.j...  \n",
       "2  http://omgili.com/ri/jHIAmI4hxg.zDiulpymXqU_n4...  \n",
       "3  http://omgili.com/ri/.0rSU5LtMgyggHgoOVy9TMDWT...  \n",
       "4  http://omgili.com/ri/.0rSU5LtMgyggHgoOVy9TMDWT...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(r\"C:\\Users\\gandh\\Google Drive\\UChicago\\11_Quarter 10\\Assignments\\Assignment 6\\webhose_cat.pkl\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english    95\n",
       "dutch       1\n",
       "german      1\n",
       "french      1\n",
       "korean      1\n",
       "italian     1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   crawled   100 non-null    object\n",
      " 1   language  100 non-null    object\n",
      " 2   text      100 non-null    object\n",
      " 3   title     100 non-null    object\n",
      " 4   url       100 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#### Even though it says all rows are not null, there are still blank Title fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Dennison's (AVY) Q4 results are likely t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuggers and Topper Industrial Carts Help Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Currently adding the following games:\\n100 (by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quote: : » Currently adding the following game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quote: : » Currently adding the following game...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Avery Dennison's (AVY) Q4 results are likely t...\n",
       "1  Tuggers and Topper Industrial Carts Help Trans...\n",
       "2  Currently adding the following games:\\n100 (by...\n",
       "3  Quote: : » Currently adding the following game...\n",
       "4  Quote: : » Currently adding the following game..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keep only English and Title column\n",
    "\n",
    "df = df[df.language=='english'].reset_index(drop=True)\n",
    "\n",
    "df = df.drop(columns=['crawled','language','url','title'])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters to avoid problems with analysis\n",
    "df['text'] = df['text'].map(lambda x: re.sub('[^a-zA-Z0-9 @ . , : - _ ]', '', str(x)))\n",
    "# In initial runs, numbers were not removed\n",
    "df['text'] = df['text'].map(lambda x: re.sub('[0-9]', '', str(x)))\n",
    "# When replacing special characters, random colons took the place. Removing those.\n",
    "df['text'] = df['text'].map(lambda x: re.sub(': :| ::', '', str(x)))\n",
    "# Initial topic modeling with textblob kept showing am pm. Need to remove\n",
    "df['text'] = df['text'].map(lambda x: re.sub('a.m|p.m', '', str(x)))\n",
    "##Lower case applied since text blob recognizes case\n",
    "df['text'] = df['text'].str.lower() \n",
    "## A lot of words less than three characters appear in topic model. Need to remove\n",
    "df['text'] = df['text'].map(lambda x: re.sub(r'\\b\\w{1,3}\\b', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avery dennisons   results  likely  gain   back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tuggers  topper industrial carts help transpor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currently adding  following games:  everything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quote  currently adding  following games:  eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quote  currently adding  following games:  eve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  avery dennisons   results  likely  gain   back...\n",
       "1  tuggers  topper industrial carts help transpor...\n",
       "2  currently adding  following games:  everything...\n",
       "3  quote  currently adding  following games:  eve...\n",
       "4  quote  currently adding  following games:  eve..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avery dennisons   results  likely  gain   back  solid momentum   segments, focus  productivity, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tuggers  topper industrial carts help transport materials between manufacturing plants  warehous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currently adding  following games:  everythingstaken  free beetles  space felony after death  ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quote  currently adding  following games:  everythingstaken  free beetles  space felony after de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quote  currently adding  following games:  everythingstaken  free beetles  space felony after de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text\n",
       "0  avery dennisons   results  likely  gain   back  solid momentum   segments, focus  productivity, ...\n",
       "1  tuggers  topper industrial carts help transport materials between manufacturing plants  warehous...\n",
       "2  currently adding  following games:  everythingstaken  free beetles  space felony after death  ha...\n",
       "3  quote  currently adding  following games:  everythingstaken  free beetles  space felony after de...\n",
       "4  quote  currently adding  following games:  everythingstaken  free beetles  space felony after de..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present N Top Topics in Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/\n",
    "\n",
    "def tf(word, blob):\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "# tf(word, blob) computes \"term frequency\" which is the number of times a word appears in a document blob, \n",
    "# normalized by dividing by the total number of words in blob. We use TextBlob for breaking up the text into words \n",
    "# and getting the word counts.\n",
    "\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "# n_containing(word, bloblist) returns the number of documents containing word. \n",
    "# A generator expression is passed to the sum() function.\n",
    "\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "# idf(word, bloblist) computes \"inverse document frequency\" which measures how common a word is \n",
    "# among all documents in bloblist. The more common a word is, the lower its idf. \n",
    "# We take the ratio of the total number of documents to the number of documents containing word, \n",
    "# then take the log of that. Add 1 to the divisor to prevent division by zero\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    return tf(word, blob) * idf(word, bloblist)\n",
    "# tfidf(word, blob, bloblist) computes the TF-IDF score. It is simply the product of tf and idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloblist = []\n",
    "del bloblist[:]\n",
    "\n",
    "for i  in range(0,len(df)):\n",
    "    bloblist.append(TextBlob(df['text'].iloc[i]))\n",
    "    \n",
    "len(bloblist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words 1\n",
      "\tWord: zacks, TF-IDF: 0.10826\n",
      "\tWord: irobot, TF-IDF: 0.06315\n",
      "\tWord: motley, TF-IDF: 0.0504\n",
      "\tWord: globenewswire, TF-IDF: 0.0504\n",
      "\tWord: fool, TF-IDF: 0.04511\n",
      "Top words 1\n",
      "\tWord: zacks, TF-IDF: 0.10826\n",
      "\tWord: irobot, TF-IDF: 0.06315\n",
      "\tWord: motley, TF-IDF: 0.0504\n",
      "\tWord: globenewswire, TF-IDF: 0.0504\n",
      "\tWord: fool, TF-IDF: 0.04511\n",
      "Top words 2\n",
      "\tWord: carts, TF-IDF: 0.11841\n",
      "\tWord: topper, TF-IDF: 0.09868\n",
      "\tWord: industrial, TF-IDF: 0.04664\n",
      "\tWord: operators, TF-IDF: 0.03947\n",
      "\tWord: handling, TF-IDF: 0.03671\n",
      "Top words 1\n",
      "\tWord: zacks, TF-IDF: 0.10826\n",
      "\tWord: irobot, TF-IDF: 0.06315\n",
      "\tWord: motley, TF-IDF: 0.0504\n",
      "\tWord: globenewswire, TF-IDF: 0.0504\n",
      "\tWord: fool, TF-IDF: 0.04511\n",
      "Top words 2\n",
      "\tWord: carts, TF-IDF: 0.11841\n",
      "\tWord: topper, TF-IDF: 0.09868\n",
      "\tWord: industrial, TF-IDF: 0.04664\n",
      "\tWord: operators, TF-IDF: 0.03947\n",
      "\tWord: handling, TF-IDF: 0.03671\n",
      "Top words 3\n",
      "\tWord: super, TF-IDF: 0.02407\n",
      "\tWord: tower, TF-IDF: 0.02078\n",
      "\tWord: adding, TF-IDF: 0.01949\n",
      "\tWord: dead, TF-IDF: 0.01949\n",
      "\tWord: dominique, TF-IDF: 0.01949\n",
      "Top words 1\n",
      "\tWord: zacks, TF-IDF: 0.10826\n",
      "\tWord: irobot, TF-IDF: 0.06315\n",
      "\tWord: motley, TF-IDF: 0.0504\n",
      "\tWord: globenewswire, TF-IDF: 0.0504\n",
      "\tWord: fool, TF-IDF: 0.04511\n",
      "Top words 2\n",
      "\tWord: carts, TF-IDF: 0.11841\n",
      "\tWord: topper, TF-IDF: 0.09868\n",
      "\tWord: industrial, TF-IDF: 0.04664\n",
      "\tWord: operators, TF-IDF: 0.03947\n",
      "\tWord: handling, TF-IDF: 0.03671\n",
      "Top words 3\n",
      "\tWord: super, TF-IDF: 0.02407\n",
      "\tWord: tower, TF-IDF: 0.02078\n",
      "\tWord: adding, TF-IDF: 0.01949\n",
      "\tWord: dead, TF-IDF: 0.01949\n",
      "\tWord: dominique, TF-IDF: 0.01949\n",
      "Top words 4\n",
      "\tWord: dungeon, TF-IDF: 0.02828\n",
      "\tWord: game, TF-IDF: 0.02629\n",
      "\tWord: super, TF-IDF: 0.02329\n",
      "\tWord: tower, TF-IDF: 0.0201\n",
      "\tWord: adding, TF-IDF: 0.01885\n",
      "Top words 1\n",
      "\tWord: zacks, TF-IDF: 0.10826\n",
      "\tWord: irobot, TF-IDF: 0.06315\n",
      "\tWord: motley, TF-IDF: 0.0504\n",
      "\tWord: globenewswire, TF-IDF: 0.0504\n",
      "\tWord: fool, TF-IDF: 0.04511\n",
      "Top words 2\n",
      "\tWord: carts, TF-IDF: 0.11841\n",
      "\tWord: topper, TF-IDF: 0.09868\n",
      "\tWord: industrial, TF-IDF: 0.04664\n",
      "\tWord: operators, TF-IDF: 0.03947\n",
      "\tWord: handling, TF-IDF: 0.03671\n",
      "Top words 3\n",
      "\tWord: super, TF-IDF: 0.02407\n",
      "\tWord: tower, TF-IDF: 0.02078\n",
      "\tWord: adding, TF-IDF: 0.01949\n",
      "\tWord: dead, TF-IDF: 0.01949\n",
      "\tWord: dominique, TF-IDF: 0.01949\n",
      "Top words 4\n",
      "\tWord: dungeon, TF-IDF: 0.02828\n",
      "\tWord: game, TF-IDF: 0.02629\n",
      "\tWord: super, TF-IDF: 0.02329\n",
      "\tWord: tower, TF-IDF: 0.0201\n",
      "\tWord: adding, TF-IDF: 0.01885\n",
      "Top words 5\n",
      "\tWord: rabbit, TF-IDF: 0.02795\n",
      "\tWord: super, TF-IDF: 0.02301\n",
      "\tWord: death, TF-IDF: 0.02183\n",
      "\tWord: tower, TF-IDF: 0.01986\n",
      "\tWord: adding, TF-IDF: 0.01863\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,6) : \n",
    "    for i, blob in enumerate(bloblist):\n",
    "    # Print top 5 values\n",
    "        if i == j:\n",
    "            break\n",
    "        print(\"Top words {}\".format(i + 1))\n",
    "        scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "        sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        for word, score in sorted_words[:5]:\n",
    "            print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in df['text']]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.8 s\n",
      "(0, '0.007*\"market\" + 0.006*\"company\" + 0.005*\"caterpillar\" + 0.005*\"plant\" + 0.004*\"year\"')\n",
      "Wall time: 14.7 s\n",
      "(0, '0.008*\"company\" + 0.007*\"market\" + 0.006*\"share\" + 0.005*\"caterpillar\" + 0.005*\"city\"')\n",
      "(1, '0.009*\"plant\" + 0.007*\"amazon\" + 0.006*\"market\" + 0.006*\"case\" + 0.005*\"sphere\"')\n",
      "Wall time: 11.3 s\n",
      "(0, '0.013*\"amazon\" + 0.008*\"sphere\" + 0.007*\"company\" + 0.007*\"seattle\" + 0.005*\"work\"')\n",
      "(1, '0.012*\"plant\" + 0.010*\"caterpillar\" + 0.008*\"case\" + 0.006*\"share\" + 0.006*\"company\"')\n",
      "(2, '0.014*\"market\" + 0.006*\"state\" + 0.006*\"city\" + 0.005*\"china\" + 0.005*\"company\"')\n",
      "Wall time: 13.5 s\n",
      "(0, '0.017*\"amazon\" + 0.012*\"sphere\" + 0.011*\"seattle\" + 0.007*\"monday\" + 0.006*\"grand\"')\n",
      "(1, '0.013*\"caterpillar\" + 0.009*\"company\" + 0.008*\"share\" + 0.007*\"product\" + 0.006*\"stock\"')\n",
      "(2, '0.020*\"plant\" + 0.013*\"case\" + 0.009*\"skid\" + 0.007*\"steer\" + 0.007*\"wardian\"')\n",
      "(3, '0.014*\"market\" + 0.008*\"company\" + 0.006*\"city\" + 0.006*\"state\" + 0.005*\"china\"')\n",
      "Wall time: 10.9 s\n",
      "(0, '0.012*\"plant\" + 0.008*\"caterpillar\" + 0.008*\"case\" + 0.007*\"median\" + 0.007*\"estimate\"')\n",
      "(1, '0.009*\"company\" + 0.007*\"health\" + 0.005*\"forklift\" + 0.005*\"care\" + 0.005*\"year\"')\n",
      "(2, '0.026*\"market\" + 0.013*\"amazon\" + 0.009*\"sphere\" + 0.009*\"industry\" + 0.009*\"report\"')\n",
      "(3, '0.008*\"blade\" + 0.007*\"skid\" + 0.006*\"pusher\" + 0.006*\"bucket\" + 0.006*\"mnubo\"')\n",
      "(4, '0.008*\"china\" + 0.007*\"repatriation\" + 0.006*\"would\" + 0.005*\"year\" + 0.005*\"profit\"')\n",
      "Wall time: 10.9 s\n",
      "(0, '0.009*\"company\" + 0.008*\"china\" + 0.007*\"repatriation\" + 0.006*\"would\" + 0.006*\"profit\"')\n",
      "(1, '0.016*\"share\" + 0.015*\"caterpillar\" + 0.012*\"company\" + 0.008*\"stock\" + 0.006*\"operation\"')\n",
      "(2, '0.036*\"market\" + 0.011*\"industry\" + 0.010*\"report\" + 0.007*\"analysis\" + 0.007*\"growth\"')\n",
      "(3, '0.010*\"product\" + 0.009*\"cart\" + 0.007*\"industrial\" + 0.007*\"mnubo\" + 0.007*\"topper\"')\n",
      "(4, '0.021*\"plant\" + 0.016*\"amazon\" + 0.012*\"case\" + 0.012*\"sphere\" + 0.011*\"seattle\"')\n",
      "(5, '0.014*\"median\" + 0.013*\"city\" + 0.012*\"estimate\" + 0.012*\"university\" + 0.010*\"town\"')\n"
     ]
    }
   ],
   "source": [
    "# Running and Trainign LDA model on the document term matrix.\n",
    "for i in range(1,7):\n",
    "    %time ldamodel = Lda(doc_term_matrix, num_topics=i, id2word = dictionary, passes=50) #3 topics\n",
    "    print(*ldamodel.print_topics(num_topics=i, num_words=5), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain how you selected N and which method you chose.\n",
    "\n",
    "Since this is a short text (just 95 rows), there shouldn't be more than 5 topics. I ran the LDA and TextBlob for 5 topics each to compare. As I was running these models, I noticed additional data cleaning that needed to be done, so I added those steps in pre-processing and reran the models. \n",
    "\n",
    "In analyzing the results, I prefer LDA as the topics seem to make more sense. It seems to take context into more account than TextBlob.\n",
    "\n",
    "With regards to the final number of topics, I likke the LDA 5 topics. It's more clear what each topic is about and there's not duplication."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
